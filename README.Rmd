---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

<!-- badges: start -->
[![R-CMD-check](https://github.com/rahulsh97/plfs/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/pachadotdev/rahulsh97/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# Periodic Labour Force Survey (PLFS)

The goal of plfs is to provide a long dataset of the Periodic Labour Force Survey (PLFS) from India.

## Example

Install the package from GitHub and load it:

```{r install, eval=FALSE}
# install.packages("devtools")
devtools::install_github("rahulsh97/plfs")
```

```{r load}
library(plfs)
```

Because of the datasets size, the package provides a function to download the datasets and create a local DuckDB
database. This results in a CRAN-compliant package.

Here is how to get the plfs database ready for use:

```{r download, eval=FALSE}
plfs_download()
```

Check the proportion of observations by Social Group (b3q4_hhv1) in the survey (See https://microdata.gov.in/NADA/index.php/catalog/213/data-dictionary/F5):

```{r avg_sector}
library(dplyr)
library(duckdb)

con <- dbConnect(duckdb(), plfs_file_path())

dbListTables(con)

tbl(con, "2021-22-hhrv") %>%
  count()

tbl(con, "2021-22-hhrv") %>%
  count(b3q4_hhrv) %>%
  mutate(
    b3q4_hhrv = case_when(
      b3q4_hhrv == 1L ~ "scheduled tribe",
      b3q4_hhrv == 2L ~ "scheduled caste",
      b3q4_hhrv == 3L ~ "other backward class",
      b3q4_hhrv == 9L ~ "other",
      TRUE ~ NA_character_
    ),
    pct = n / sum(n)
  ) %>%
  collect()

# what happened from 2021 to 2022

d <- tbl(con, "2021-22-hhrv") %>%
  count(b3q4_hhrv) %>%
  mutate(
    b3q4_hhrv = case_when(
      b3q4_hhrv == 1L ~ "scheduled tribe",
      b3q4_hhrv == 2L ~ "scheduled caste",
      b3q4_hhrv == 3L ~ "other backward class",
      b3q4_hhrv == 9L ~ "other",
      TRUE ~ NA_character_
    ),
    pct = n / sum(n)
  ) %>%
  left_join(
    tbl(con, "2022-23-hhrv") %>%
      count(b3q4_hhrv) %>%
      mutate(
        b3q4_hhrv = case_when(
          b3q4_hhrv == 1L ~ "scheduled tribe",
          b3q4_hhrv == 2L ~ "scheduled caste",
          b3q4_hhrv == 3L ~ "other backward class",
          b3q4_hhrv == 9L ~ "other",
          TRUE ~ NA_character_
        ),
        pct = n / sum(n)
      ),
      by = "b3q4_hhrv"
  ) %>%
  collect()

dbDisconnect(con, shutdown = TRUE)
```

# Adding older/newer years

Be sure to use the yearly survey (e.g., Jul 23 - Jun 24, https://microdata.gov.in/NADA/index.php/catalog/PLFS/?page=1&sort_order=desc&ps=15&repo=PLFS)

1. Install the Nesstar Explorer (e.g. plfs 2023-24 includes it)
2. Extract the RAR/ZIP files downloaded from the microdata website to data-raw/202324 or what year you are adding
3. Export the .Nesstar file to Stata (SAV) format with "Export Datasets" and the metadata with "Export DDI" using the Nesstar Explorer
4. Update `00-tidy-data.r` and run it
5. Update the available datasets in `R/available_datasets.R`
6. Update the new RDS files in the 'Releases' section of the GitHub repository
7. Regenerate the database with `plfs_delete()` and `plfs_download()`
